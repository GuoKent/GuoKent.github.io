<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/undefined/"/>
    <url>/undefined/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch 分布式训练</title>
    <link href="/developnotes/distribute/"/>
    <url>/developnotes/distribute/</url>
    
    <content type="html"><![CDATA[<h2 id="手动配置分布式训练"><a href="#手动配置分布式训练" class="headerlink" title="手动配置分布式训练"></a>手动配置分布式训练</h2><p>该方法自定义程度化较高，但环境等需自己配置，代码写起来较繁杂</p><h3 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.nn.parallel <span class="hljs-keyword">import</span> DistributedDataParallel <span class="hljs-keyword">as</span> DDP<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">setup_distributed</span>(<span class="hljs-params">rank, world_size</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    初始化分布式环境</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    os.environ[<span class="hljs-string">&quot;MASTER_ADDR&quot;</span>] = <span class="hljs-string">&quot;127.0.0.1&quot;</span>  <span class="hljs-comment"># 本机地址</span><br>    os.environ[<span class="hljs-string">&quot;MASTER_PORT&quot;</span>] = <span class="hljs-string">&quot;29946&quot;</span>  <span class="hljs-comment"># 端口号，任取一个空端口就行</span><br>    dist.init_process_group(<br>        backend=<span class="hljs-string">&#x27;nccl&#x27;</span>,  <span class="hljs-comment"># NCCL 是 GPU 上分布式训练的推荐后端</span><br>        init_method=<span class="hljs-string">&#x27;env://&#x27;</span>,  <span class="hljs-comment"># 使用环境变量初始化</span><br>        rank=rank,<br>        world_size=world_size<br>    )<br>    torch.cuda.set_device(rank)  <span class="hljs-comment"># 将当前进程绑定到 rank 对应的 GPU</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_model</span>(<span class="hljs-params">model, rank</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    将 torch.model 放入分布式模型中</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># model = model.to(rank)  # 将模型移动到 rank 对应的 GPU</span><br>    executor = model._nn_executor.model.to(rank)  <span class="hljs-comment"># 将模型中torch.model部分放入gpu</span><br>    ddp_model = DDP(executor, device_ids=[rank])  <span class="hljs-comment"># 使用 DDP 包装模型(torch.model类)</span><br>    <span class="hljs-keyword">return</span> ddp_model<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_data</span>(<span class="hljs-params">dataset, rank, world_size, batch_size, collate_fn=<span class="hljs-literal">None</span>, num_workers=<span class="hljs-number">0</span></span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    数据并行, 数据转为分布式数据</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank, shuffle=<span class="hljs-literal">False</span>)<br>    dataloader = DataLoader(dataset, <br>                            batch_size=batch_size, <br>                            sampler=sampler, <br>                            collate_fn=collate_fn, <br>                            num_workers=num_workers,<br>                            pin_memory=<span class="hljs-literal">True</span>,<br>                            prefetch_factor=<span class="hljs-number">8</span>,<br>                            persistent_workers=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> dataloader<br></code></pre></td></tr></table></figure><ul><li><code>num_workers</code> 线程数，一般去cpu线程数的 1&#x2F;2，或取gpu数量。但取多了会占大量内存</li><li><code>pin_memory</code> 固定数据在内存中的地址，可加快读取速度，但可能会导致占用内存大</li><li><code>prefetch_factor</code> 预先取多少个batch到内存中，默认为2，调大可加快读取速度</li><li><code>persistent_workers</code> 每次迭代结束是否保留进程，默认为False，可加快读写速度</li><li><code>collate_fn</code> 默认将 <code>[(data 1, label 1), (data 2, label 2), …]</code> 转化为<code>[[data 1, data 2, ...], [label 1, label 2, ...]]</code> 若要自定义<code>collate_fn</code> 则需自行转换</li></ul><h3 id="执行函数"><a href="#执行函数" class="headerlink" title="执行函数"></a>执行函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">model, dataset</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    主运行函数 (主进程)</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    world_size = torch.cuda.device_count()<br>    mp.spawn(<br>        inference,  <span class="hljs-comment"># 传入推理/训练函数, 默认会把第一个rank参数传入</span><br>        args=(world_size, model, dataset),  <span class="hljs-comment"># 推理/训练函数的其他参数</span><br>        nprocs=world_size,<br>        join=<span class="hljs-literal">True</span><br>    )<br>    ...<br> <br> <span class="hljs-keyword">def</span> <span class="hljs-title function_">inference</span>(<span class="hljs-params">rank, world_size, model, dataset</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    推理/训练函数 (每个gpu执行的函数)</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        rank: 当前 gpu 对应的 rank</span><br><span class="hljs-string">        world_size: gpu 总数</span><br><span class="hljs-string">        model: torch.model</span><br><span class="hljs-string">        dataset: torch.dataset</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># 初始化分布式环境</span><br>    setup_distributed(rank, world_size)<br>    <span class="hljs-comment"># 准备模型</span><br>    ddp_model: DDP = prepare_model(model, rank)<br>    <span class="hljs-comment"># 准备数据</span><br>    dataloader = prepare_data(dataset, rank, world_size, batch_size=BATCH_SIZE, collate_fn=<span class="hljs-literal">None</span>, num_workers=NUM_WORKERS)<br>    <span class="hljs-comment"># 推理</span><br>    ddp_model.<span class="hljs-built_in">eval</span>()<br>    fail_batch = <span class="hljs-number">0</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Begin inference, model rank: <span class="hljs-subst">&#123;rank&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tqdm(dataloader, total=<span class="hljs-built_in">len</span>(dataloader)):<br></code></pre></td></tr></table></figure><h3 id="结果写入和保存"><a href="#结果写入和保存" class="headerlink" title="结果写入和保存"></a>结果写入和保存</h3><p>由于是多卡推理&#x2F;训练，涉及到文件读写冲突问题，因此需要制定策略防止文件写冲突</p><ul><li>每张卡各自写到自己的文件，整个训练&#x2F;推理过程结束完最后再合并（推荐，并行写入更快）</li><li>只有一个结果文件，每张卡轮流写入（进程写入结果文件要排队，降低效率）<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> fcntl<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">write_result_to_file</span>(<span class="hljs-params">batch, results, rank</span>):<br><span class="hljs-string">&#x27;&#x27;&#x27; 每个线程的结果写入临时文件, 或者单独写入一个文件&#x27;&#x27;&#x27;</span><br>sim_temp_path = <span class="hljs-string">f&quot;./res/temp/results_rank_<span class="hljs-subst">&#123;rank&#125;</span>.txt&quot;</span><br>    is_header = <span class="hljs-literal">False</span> <span class="hljs-keyword">if</span> os.path.exists(sim_temp_path) <span class="hljs-keyword">else</span> <span class="hljs-literal">True</span><br>    <br>    <span class="hljs-comment"># ... 结果处理，得到写入文件的格式</span><br>    new_df = pd.DataFrame(new_rows)  <span class="hljs-comment"># 要写入文件的格式</span><br>    <br>    <span class="hljs-comment"># 写入临时文件</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(sim_temp_path, <span class="hljs-string">&#x27;a&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        <span class="hljs-comment"># 独占锁</span><br>        fcntl.flock(f, fcntl.LOCK_EX)<br>        <span class="hljs-keyword">try</span>:<br>            new_df.to_csv(f, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, index=<span class="hljs-literal">False</span>, header=is_header, mode=<span class="hljs-string">&#x27;a&#x27;</span>)<br>        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Raise Error: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)<br>        <span class="hljs-keyword">finally</span>:<br>            <span class="hljs-comment"># 解锁</span><br>            fcntl.flock(f, fcntl.LOCK_UN)<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    当 num_workers 设定大于gpu数量时，一个gpu可能会执行多个线程的任务。</span><br><span class="hljs-string">    当线程1再cuda:0上执行完，然后执行写入临时文件。若线程1的写文件还没执行完，线程2也在</span><br><span class="hljs-string">    cuda:0上执行完，也开始写入临时文件，就会发生冲突</span><br><span class="hljs-string">    因此需要一个互斥锁来保证两者的写操作冲突</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br> <br> <span class="hljs-keyword">def</span> <span class="hljs-title function_">merge_results_from_files</span>(<span class="hljs-params">world_size, save_path</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    将每个gpu的结果合并到一起</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    is_header = <span class="hljs-literal">False</span> <span class="hljs-keyword">if</span> os.path.exists(save_path) <span class="hljs-keyword">else</span> <span class="hljs-literal">True</span><br>    <span class="hljs-comment"># 合并每个rank的结果</span><br>    <span class="hljs-keyword">for</span> rank <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(world_size):<br>        sim_temp_path = <span class="hljs-string">f&quot;./res/temp/results_rank_<span class="hljs-subst">&#123;rank&#125;</span>.txt&quot;</span><br>        rank_file = pd.read_table(sim_temp_path, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>)<br>        rank_file.to_csv(save_path, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, index=<span class="hljs-literal">False</span>, header=is_header, mode=<span class="hljs-string">&#x27;a&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Finish merge file to: <span class="hljs-subst">&#123;save_path&#125;</span>&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">delete_temp_file</span>():<br>    <span class="hljs-string">&#x27;&#x27;&#x27;删除临时文件(可选)&#x27;&#x27;&#x27;</span><br>    temp_folder = <span class="hljs-string">&quot;./res/temp/&quot;</span><br>    temp_file_names = [<span class="hljs-string">f&quot;results_rank_<span class="hljs-subst">&#123;rank&#125;</span>.txt&quot;</span> <span class="hljs-keyword">for</span> rank <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(torch.cuda.device_count())]<br>    <span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> temp_file_names:<br>        file_path = os.path.join(temp_folder, file_name)<br>        <span class="hljs-keyword">if</span> os.path.isfile(file_path):<br>            <span class="hljs-keyword">try</span>:<br>                os.remove(file_path)<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Delete file: <span class="hljs-subst">&#123;file_path&#125;</span> successfully&quot;</span>)<br>            <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Raise Error when delete <span class="hljs-subst">&#123;file_path&#125;</span>: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure></li></ul><h2 id="自动配置分布式训练"><a href="#自动配置分布式训练" class="headerlink" title="自动配置分布式训练"></a>自动配置分布式训练</h2><p>另一种分布式训练写法，就是使用torchrun来执行python文件。运行的主函数只需关注每一个gpu的代码怎么运行即可，torchrun会自动分配环境给每一gpu。该方法只需考虑每个 gpu 对应的执行函数即可，代码写起来较为简单，也无需考虑文件互斥的问题，运行时直接 torchrun 自动执行分布式环境</p><blockquote><p>一个典型的例子：<a href="https://github.com/OFA-Sys/Chinese-CLIP/blob/master/cn_clip/training/main.py">CLIP</a></p></blockquote><h3 id="执行函数-1"><a href="#执行函数-1" class="headerlink" title="执行函数"></a>执行函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn.parallel.DistributedDataParallel <span class="hljs-keyword">as</span> DistributedDataParallel<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    每个 gpu 的执行函数</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    args = parse_args()<br>    <br>    <span class="hljs-comment"># 查看当前gpu是哪个rank</span><br>    args.local_device_rank = <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&quot;LOCAL_RANK&quot;</span>])<br>    torch.cuda.set_device(args.local_device_rank)<br>    args.device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>, args.local_device_rank)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Init process group...&quot;</span>)  <span class="hljs-comment"># 准备环境</span><br>    dist.init_process_group(backend=<span class="hljs-string">&quot;nccl&quot;</span>, init_method=<span class="hljs-string">&#x27;env://&#x27;</span>)<br>    args.rank = dist.get_rank()<br>    args.world_size = dist.get_world_size()<br>    <br>    <span class="hljs-comment"># 准备模型</span><br>    model = MyModel()  <span class="hljs-comment"># 定义自己的模型</span><br>    model = DistributedDataParallel(model, ...)  <span class="hljs-comment"># 放入分布式模型里</span><br>    <br>    <span class="hljs-comment"># 准备数据集</span><br>    dataset = MyDataset()<br>    sampler = DistributedSampler(dataset, shuffle=<span class="hljs-literal">True</span>, seed=args.seed)<br>    dataloader = DataLoader(<br>        dataset,<br>        batch_size=batch_size,<br>        pin_memory=<span class="hljs-literal">False</span>,<br>        num_workers=args.num_workers <span class="hljs-keyword">if</span> is_train <span class="hljs-keyword">else</span> args.valid_num_workers,<br>        sampler=sampler,<br>        collate_fn=collate_fn<br>    )<br>    <br>    <span class="hljs-comment"># 优化器</span><br>    optimizer = optim.AdamW(...)<br>    <br>    <span class="hljs-comment"># 训练</span><br>    train(model, ...)<br> <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>main()<br></code></pre></td></tr></table></figure><h3 id="执行脚本"><a href="#执行脚本" class="headerlink" title="执行脚本"></a>执行脚本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">默认8卡全部</span><br>nohup torchrun --nproc_per_node=8 --master_port=29500 train_cnclip.py --max-epochs 10 --use-augment &gt; ./logs/train.log 2&gt;&amp;1 &amp;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">指定其中几张卡(默认按顺序取)</span><br>nohup CUDA_VISIBLE_DEVICES=0,1,2,3 torchrun --nproc_per_node=4 --master_port=29500 train_cnclip.py --max-epochs 10 --use-augment &gt; ./logs/train.log 2&gt;&amp;1 &amp;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">默认按顺序取前4张卡</span><br>nohup torchrun --nproc_per_node=4 --master_port=29500 train_cnclip.py --max-epochs 10 --use-augment &gt; ./logs/train.log 2&gt;&amp;1 &amp;<br><br><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>开发笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>开发</tag>
      
      <tag>Pytorch</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker 操作</title>
    <link href="/developnotes/docker/"/>
    <url>/developnotes/docker/</url>
    
    <content type="html"><![CDATA[<h3 id="创建镜像"><a href="#创建镜像" class="headerlink" title="创建镜像"></a>创建镜像</h3><p>通常，创建 Docker 镜像的方法是通过 <code>Dockerfile</code> 文件。<code>Dockerfile</code> 是一个文本文件，包含了构建镜像所需的所有指令。</p><h5 id="基于-Ubuntu-创建-Python-环境"><a href="#基于-Ubuntu-创建-Python-环境" class="headerlink" title="基于 Ubuntu 创建 Python 环境"></a>基于 Ubuntu 创建 Python 环境</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用官方 Ubuntu 镜像作为基础镜像</span><br>FROM ubuntu:<span class="hljs-number">20.04</span><br><br><span class="hljs-comment"># 设置环境变量，防止在安装过程中出现交互式提示</span><br>ENV DEBIAN_FRONTEND=noninteractive<br><br><span class="hljs-comment"># 更新镜像并安装 Python 和 pip</span><br>RUN apt-get update &amp;&amp; apt-get install -y python3 python3-pip<br><br><span class="hljs-comment"># 设置工作目录</span><br>WORKDIR /app<br><br><span class="hljs-comment"># 将本地目录的代码复制到容器内</span><br>COPY . /app<br><br><span class="hljs-comment"># 安装 Python 依赖（假设有 requirements.txt 文件）</span><br>RUN pip3 install -r requirements.txt<br><br><span class="hljs-comment"># 默认运行命令</span><br>CMD [<span class="hljs-string">&quot;python3&quot;</span>, <span class="hljs-string">&quot;app.py&quot;</span>]<br></code></pre></td></tr></table></figure><h5 id="基于-Python-官方镜像"><a href="#基于-Python-官方镜像" class="headerlink" title="基于 Python 官方镜像"></a>基于 Python 官方镜像</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用官方 Python 3.9 镜像作为基础镜像</span><br>FROM python:<span class="hljs-number">3.9</span>-slim<br><br><span class="hljs-comment"># 设置工作目录</span><br>WORKDIR /app<br><br><span class="hljs-comment"># 复制当前目录内容到容器中的工作目录</span><br>COPY . /app<br><br><span class="hljs-comment"># 安装 Python 依赖</span><br>RUN pip install -r requirements.txt<br><br><span class="hljs-comment"># 运行 Python 应用</span><br>CMD [<span class="hljs-string">&quot;python&quot;</span>, <span class="hljs-string">&quot;app.py&quot;</span>]<br></code></pre></td></tr></table></figure><p>在包含 <code>Dockerfile</code> 文件的目录中运行以下命令来构建镜像：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">docker build -t mylocalenv:latest .<br></code></pre></td></tr></table></figure><ul><li><code>-t mylocalenv:latest</code> 用于为镜像指定一个标签（这里是 <code>mylocalenv</code>）。</li><li><code>.</code> 表示当前目录是构建上下文。</li></ul><h3 id="拉取现有镜像"><a href="#拉取现有镜像" class="headerlink" title="拉取现有镜像"></a>拉取现有镜像</h3><p><code>docker pull [OPTIONS] NAME[:TAG|@DIGEST]</code>  &#x2F;&#x2F; <strong>拉取镜像(下载)</strong></p><ul><li>NAME: 镜像名称，通常包含注册表地址（如 <a href="http://docker.io/library/ubuntu%EF%BC%89">docker.io&#x2F;library&#x2F;ubuntu）</a></li><li>TAG(可选)：镜像标签</li><li>DIGEST(可选)：镜像SHA256摘要</li></ul><p>例如：<code>docker pull continuumio/anaconda3</code> 从网上拉最常用的 Anaconda3 镜像</p><h3 id="启动容器并进入环境"><a href="#启动容器并进入环境" class="headerlink" title="启动容器并进入环境"></a>启动容器并进入环境</h3><p>常用指令：<code>docker run -it -v /mnt:/workspace/data my_env bash</code> </p><ul><li><code>-v</code> 代表挂在本地盘到容器中，让容器能访问本地磁盘</li><li><code>/mnt</code> 是本地磁盘路径，<code>/workspace/data</code> 是容器内部路径</li><li><code>bash</code> 代表我们希望用bash，看情况而加，若报错则不加</li><li><code>my_env</code> 是镜像名字</li></ul><h3 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h3><p><code>docker exec -it mycontainer bash</code><br><code>docker images</code> 列出镜像列表<br><code>docker ps -a</code> 列出所有容器，<code>-a</code> 代表所有<br><code>docker start mycontainer</code> 启动容器<br><code>docker stop mycontainer</code> 停止容器<br><code>docker kil mycontainer</code> 杀死容器<br><code>docker rm mycontainer</code> 删除容器<br><code>docker rmi myimage</code> 删除镜像（需删除关联容器）<br><code>Ctrl + D</code> 退出容器</p><h3 id="保存容器为新镜像"><a href="#保存容器为新镜像" class="headerlink" title="保存容器为新镜像"></a>保存容器为新镜像</h3><p><code>docker commit -a &#39;author&#39; -m &#39;instruction&#39; mycontainer new_image</code> 保存为新镜像<br><code>docker save -o tar_name.tar image_name</code> 将镜像保存为压缩包<br><code>docker load -i tar_name.tar</code> 读取压缩包镜像，然后用 <code>docker images</code> 就能看到一个新镜像</p><h3 id="本地-文件-环境-传入容器"><a href="#本地-文件-环境-传入容器" class="headerlink" title="本地 文件&#x2F;环境 传入容器"></a>本地 文件&#x2F;环境 传入容器</h3><p><code>docker cp /home/b/miniconda3/envs/py39 mycontainer:/opt/conda/envs</code><br>将本地的<code>py39</code>环境复制到容器<code>mycontainer</code>中</p>]]></content>
    
    
    <categories>
      
      <category>开发笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>开发</tag>
      
      <tag>docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Git 笔记</title>
    <link href="/developnotes/git/"/>
    <url>/developnotes/git/</url>
    
    <content type="html"><![CDATA[<h3 id="git-clone"><a href="#git-clone" class="headerlink" title="git clone"></a>git clone</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">git clone：<br>git clone http://xxxx.git  // 默认master分支<br>git clone -b &lt;branch_name&gt; http://xxxx.git  // clone指定分支<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-built_in">clone</span> 特定版本/分支</span><br>git clone -branch &lt;branch-name&gt; &lt;repo-address&gt;  // 克隆特定分支<br>git tag  // 列出全部tag(先clone全部仓库)<br>git checkout &lt;tag&gt;  // 切换到指定tag(版本)<br></code></pre></td></tr></table></figure><h3 id="连接仓库-remote"><a href="#连接仓库-remote" class="headerlink" title="连接仓库 remote"></a>连接仓库 remote</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">git remote -v  // 查看当前连接<br>git remote remove origin  // 删除现有连接<br>git remote add origin 你的远程库地址  // 把本地库与远程库关联<br></code></pre></td></tr></table></figure><h3 id="git-提交"><a href="#git-提交" class="headerlink" title="git 提交"></a>git 提交</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">第一次提交</span><br>git init   // 初始化版本库<br>git add .   // 添加文件到版本库（只是添加到缓存区），.代表添加文件夹下所有文件<br>git add -f &lt;路径&gt;  // 添加被忽略文件<br>git commit -m &quot;first commit&quot; // 把添加的文件提交到版本库，并填写提交备注<br>git push -u origin master    // 第一次推送时<br>git push  // 第一次推送后，直接使用该命令即可推送修改<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">后续提交</span><br>git add .<br>git commit -m &quot;message&quot;<br>git push origin master<br>git push origin &lt;new-brance&gt;  // master无法访问时用新分支 new-branch<br></code></pre></td></tr></table></figure><h3 id="远程更新代码"><a href="#远程更新代码" class="headerlink" title="远程更新代码"></a>远程更新代码</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">git pull origin<br>git pull origin &lt;branch&gt;  // 初次, 指定分支<br></code></pre></td></tr></table></figure><h3 id="分支操作"><a href="#分支操作" class="headerlink" title="分支操作"></a>分支操作</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">git branch --list  // 查看分支<br>git branch -m new-name  // 分支重命名<br>git checkout &lt;branch-name&gt;  // 切换到分支<br>git checkout -b &lt;branch-name&gt; // 新建分支<br>git merge target_branch  // 将目标分支合并到当前分支<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>开发笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>开发</tag>
      
      <tag>git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python</title>
    <link href="/developnotes/python/"/>
    <url>/developnotes/python/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>开发笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>开发</tag>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>xxxxx test</title>
    <link href="/papernotes/test/"/>
    <url>/papernotes/test/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>论文笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>docker</tag>
      
      <tag>论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
